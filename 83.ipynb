{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "12xXAItV_Q1yC0bM_BwSUApHznwC0efrl",
      "authorship_tag": "ABX9TyOdj+3+m+qFFP57RHTN02zi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6656f54587914d81b8707c0913fda217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58cf4fb70b654224b09a4722fcd3ba22",
              "IPY_MODEL_9fef9de50dc945709a4c66d2e4c9a75a",
              "IPY_MODEL_ac8252ea0d3e43548e38477a37034e2b"
            ],
            "layout": "IPY_MODEL_00b1ceda69bb46038e1457f86ad0f7d7"
          }
        },
        "58cf4fb70b654224b09a4722fcd3ba22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_106bb20e73f24e23967d326f4025046b",
            "placeholder": "​",
            "style": "IPY_MODEL_602262ce771a4c20b6a5ac7c377e0bdf",
            "value": "Map: 100%"
          }
        },
        "9fef9de50dc945709a4c66d2e4c9a75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9229a46d57ff46e49d188f60f99b61ac",
            "max": 1194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54f09a9ac76d408895be31f561e7c36b",
            "value": 1194
          }
        },
        "ac8252ea0d3e43548e38477a37034e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ef7cde15bbc4d508d0f090de6c89c35",
            "placeholder": "​",
            "style": "IPY_MODEL_85c5b0ef130e48f3a8765badc5ed6c21",
            "value": " 1194/1194 [00:01&lt;00:00, 851.51 examples/s]"
          }
        },
        "00b1ceda69bb46038e1457f86ad0f7d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106bb20e73f24e23967d326f4025046b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "602262ce771a4c20b6a5ac7c377e0bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9229a46d57ff46e49d188f60f99b61ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f09a9ac76d408895be31f561e7c36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ef7cde15bbc4d508d0f090de6c89c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85c5b0ef130e48f3a8765badc5ed6c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dbbbea872e249559e03b02db39b3f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfacac2f9c124e0c8f53734db3fdaa56",
              "IPY_MODEL_8fef12586fb3438a9eb8ce442833dd8e",
              "IPY_MODEL_6fcb9c86cc8448c889b09a6b1932913f"
            ],
            "layout": "IPY_MODEL_bad4fa8524244d4e81ec82ddff8c1871"
          }
        },
        "cfacac2f9c124e0c8f53734db3fdaa56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd525f519f2a424d94a91442f0cee36b",
            "placeholder": "​",
            "style": "IPY_MODEL_a13d1b84d8084cfe831ecd0e44658e55",
            "value": "Map: 100%"
          }
        },
        "8fef12586fb3438a9eb8ce442833dd8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5620d5e2e0e24f28af97c539225d59aa",
            "max": 211,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8d1644c475049828506e5c7f610670d",
            "value": 211
          }
        },
        "6fcb9c86cc8448c889b09a6b1932913f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc009dbbfea34e86b5b367ace8bde3fd",
            "placeholder": "​",
            "style": "IPY_MODEL_eb5fc23dfbbf4fffacd705edb0428e80",
            "value": " 211/211 [00:00&lt;00:00, 950.33 examples/s]"
          }
        },
        "bad4fa8524244d4e81ec82ddff8c1871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd525f519f2a424d94a91442f0cee36b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a13d1b84d8084cfe831ecd0e44658e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5620d5e2e0e24f28af97c539225d59aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d1644c475049828506e5c7f610670d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc009dbbfea34e86b5b367ace8bde3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb5fc23dfbbf4fffacd705edb0428e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25f36d6ed07249c9a69bdf9be7631634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbf4cd85419343629a08bda513572852",
              "IPY_MODEL_2fea35b8c9a34238885c8fe4e54db56d",
              "IPY_MODEL_b65be588f29948d7a402312332a56b73"
            ],
            "layout": "IPY_MODEL_6b99c7b625164342856db1e26537725e"
          }
        },
        "dbf4cd85419343629a08bda513572852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ffd49b4ace4e7a820fae05b1b6f130",
            "placeholder": "​",
            "style": "IPY_MODEL_cc6c573956064bfd896e6c38d2b27456",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2fea35b8c9a34238885c8fe4e54db56d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c430f709a6964d28ac9134d26b35656b",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8eb8676103a74905883ec6d6e1fb753c",
            "value": 4
          }
        },
        "b65be588f29948d7a402312332a56b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0f55c8460844f5c8691a26b9c7ee9c7",
            "placeholder": "​",
            "style": "IPY_MODEL_64b0c5bfd5e941a3a4804e9ea5f71db4",
            "value": " 4/4 [00:18&lt;00:00,  3.81s/it]"
          }
        },
        "6b99c7b625164342856db1e26537725e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ffd49b4ace4e7a820fae05b1b6f130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc6c573956064bfd896e6c38d2b27456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c430f709a6964d28ac9134d26b35656b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eb8676103a74905883ec6d6e1fb753c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0f55c8460844f5c8691a26b9c7ee9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b0c5bfd5e941a3a4804e9ea5f71db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f125069b89f4a1d9ff5f347ae656b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fdc4e8fd4724f7fb7fce4ee3a271b47",
              "IPY_MODEL_172df847c9ab46c78b43919cbdb07ec1",
              "IPY_MODEL_01ab1bc491344cc192a516d53d5c1036"
            ],
            "layout": "IPY_MODEL_37bbaa7c401644008ef3021445c4640c"
          }
        },
        "6fdc4e8fd4724f7fb7fce4ee3a271b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df43b29d67084660b10e517b4e339b1e",
            "placeholder": "​",
            "style": "IPY_MODEL_fe2413ba91134e99859f15e57cabefa3",
            "value": "Truncating train dataset: 100%"
          }
        },
        "172df847c9ab46c78b43919cbdb07ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81d96256558140f991e12fb5e78f9cc1",
            "max": 1194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91ad00bdde5e4dafb7d61e605110e588",
            "value": 1194
          }
        },
        "01ab1bc491344cc192a516d53d5c1036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64813d97f6674b83b5cfafb949ca52d7",
            "placeholder": "​",
            "style": "IPY_MODEL_8c1244dc079c49e186ae5988f285e484",
            "value": " 1194/1194 [00:00&lt;00:00, 31414.26 examples/s]"
          }
        },
        "37bbaa7c401644008ef3021445c4640c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df43b29d67084660b10e517b4e339b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe2413ba91134e99859f15e57cabefa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81d96256558140f991e12fb5e78f9cc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ad00bdde5e4dafb7d61e605110e588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64813d97f6674b83b5cfafb949ca52d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1244dc079c49e186ae5988f285e484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "add66cac664e4c04ae8d7048767cbd29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4547a86f2f144a9a9db9b4fd3e0fdc73",
              "IPY_MODEL_255687b6564f46bbace37a5435f74ac3",
              "IPY_MODEL_e1bcd66e2062401bbe01739b7cd6311a"
            ],
            "layout": "IPY_MODEL_1da5b410b3fe4359b6490099e82dbb9f"
          }
        },
        "4547a86f2f144a9a9db9b4fd3e0fdc73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4985246588849ee8e64f45b955de405",
            "placeholder": "​",
            "style": "IPY_MODEL_a901d1a763be496a80a8b52bfec37f29",
            "value": "Truncating eval dataset: 100%"
          }
        },
        "255687b6564f46bbace37a5435f74ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2ccfe46b133468f9db288b7418ec54a",
            "max": 211,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_846d73fe7839457099aadf9ebd756847",
            "value": 211
          }
        },
        "e1bcd66e2062401bbe01739b7cd6311a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aae74089ca64aceb01ec9bd64217676",
            "placeholder": "​",
            "style": "IPY_MODEL_0f2d656ef48d4a32a37b684c5cd00f42",
            "value": " 211/211 [00:00&lt;00:00, 13612.21 examples/s]"
          }
        },
        "1da5b410b3fe4359b6490099e82dbb9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4985246588849ee8e64f45b955de405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a901d1a763be496a80a8b52bfec37f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2ccfe46b133468f9db288b7418ec54a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "846d73fe7839457099aadf9ebd756847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3aae74089ca64aceb01ec9bd64217676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f2d656ef48d4a32a37b684c5cd00f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e31101d255d3498bb0bc3584329948bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3922ac9bfe764ee39d3bcd2ffd5ada94",
              "IPY_MODEL_a8515287267146b6b31e099a860f37e6",
              "IPY_MODEL_a28ca95b7c334a0aa251b5a1f00c089e"
            ],
            "layout": "IPY_MODEL_4e27f15d531c4a9694adcc5c6da8c12d"
          }
        },
        "3922ac9bfe764ee39d3bcd2ffd5ada94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef8f6c0120e4289b9f6b394a3ecde56",
            "placeholder": "​",
            "style": "IPY_MODEL_438517d16fa1421ba986e43b13507958",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a8515287267146b6b31e099a860f37e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_274099e88d2b43c2a82e21185bd87568",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d8eda4f00584e6185f234d6b7fbf5fa",
            "value": 4
          }
        },
        "a28ca95b7c334a0aa251b5a1f00c089e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c054c91a264f4fb61246612839ceb6",
            "placeholder": "​",
            "style": "IPY_MODEL_83a154bf5b054defbe7dad9fcad5147a",
            "value": " 4/4 [00:04&lt;00:00,  1.10it/s]"
          }
        },
        "4e27f15d531c4a9694adcc5c6da8c12d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef8f6c0120e4289b9f6b394a3ecde56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438517d16fa1421ba986e43b13507958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "274099e88d2b43c2a82e21185bd87568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d8eda4f00584e6185f234d6b7fbf5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08c054c91a264f4fb61246612839ceb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a154bf5b054defbe7dad9fcad5147a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lingche1/msc1/blob/main/83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQXi7hIoauS-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d642fa33"
      },
      "source": [
        "# Task\n",
        "使用 \"https://huggingface.co/Weyaxi/Einstein-v6.1-Llama3-8B\" 模型，对 \"/content/dataset_7_30-finnal_1.json\" 数据集进行 QLoRA 微调，数据集包含 instruction, output 和 system 字段，训练时划分 15% 的验证集。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed72ef8d"
      },
      "source": [
        "## 环境准备\n",
        "\n",
        "### Subtask:\n",
        "安装必要的库，如 `transformers`, `peft`, `bitsandbytes`, `trl` 等。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5b5a2cc"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the necessary libraries for QLoRA fine-tuning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04a69552",
        "outputId": "1f40ffe3-7e32-4db1-925e-40336b24d6db"
      },
      "source": [
        "%pip install transformers peft bitsandbytes trl wandb np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.20.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: np in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.9.0)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.0.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.12.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "278e6c3a"
      },
      "source": [
        "## 加载数据集\n",
        "\n",
        "### Subtask:\n",
        "从 `/content/dataset_7_30-finnal_1.json` 文件加载数据集。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb516234"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary function and load the dataset from the specified JSON file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44f56306",
        "outputId": "a38602df-eeb6-46e6-f5dd-7eb1adadb162"
      },
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/dataset82_restructured.json\", split=\"train\")\n",
        "print(dataset)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['instruction', 'input', 'output'],\n",
            "    num_rows: 1405\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffd0405a"
      },
      "source": [
        "## 数据处理\n",
        "\n",
        "### Subtask:\n",
        "将数据集格式化为模型训练所需的格式，并按照 85:15 的比例划分训练集和验证集。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23e2f6f8"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the formatting function, apply it to the dataset, and then split the dataset into training and validation sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10608474",
        "outputId": "5b3cfb7f-e383-45ba-a027-f6b735bec706"
      },
      "source": [
        "def format_data(example):\n",
        "    if example.get('input') and example['input'].strip():\n",
        "        prompt = f\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['input']}\\n\\n### Response:\\n{example['output']}\"\n",
        "    else:\n",
        "        prompt = f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n{example['output']}\"\n",
        "    return prompt\n",
        "\n",
        "formatted_dataset = dataset.map(lambda x: {\"text\": format_data(x)})\n",
        "\n",
        "train_test_split = formatted_dataset.train_test_split(test_size=0.15)\n",
        "train_dataset = train_test_split['train']\n",
        "eval_dataset = train_test_split['test']\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": np.mean(predictions == labels)}\n",
        "print(\"Training dataset size:\", len(train_dataset))\n",
        "print(\"Validation dataset size:\", len(eval_dataset))\n",
        "print(\"First formatted example in training set:\")\n",
        "print(train_dataset[0]['text'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 1194\n",
            "Validation dataset size: 211\n",
            "First formatted example in training set:\n",
            "### Instruction:\n",
            "You are QuantumMentor, an AI teaching assistant with advanced expertise in Quantum Materials Science and Photonic Materials.\n",
            "\n",
            "Your academic foundation spans the core disciplines of physics, materials science, and applied optics, with a strong emphasis on the theoretical and computational frameworks that underlie modern quantum and photonic material systems.\n",
            "\n",
            "Your primary responsibility is to accurately answer complex questions while helping master's and advanced undergraduate students **understand** the physical principles and mathematical reasoning involved.\n",
            "\n",
            "Your answers must satisfy two goals:\n",
            "- Provide technically correct and complete solutions.\n",
            "- Promote conceptual understanding and learning.\n",
            "\n",
            "To achieve this, follow these principles:\n",
            "\n",
            "1. **Structured Explanation**  \n",
            "   - Start with core physical or material concepts.  \n",
            "   - Proceed step by step toward mathematical formulations.  \n",
            "   - Conclude with physical interpretation and application.  \n",
            "\n",
            "2. **Scientific Precision**  \n",
            "   - Use correct and complete LaTeX equations.  \n",
            "   - Define all variables and symbols clearly.  \n",
            "   - State all assumptions and applicable regimes.\n",
            "\n",
            "3. **Terminology Clarity**  \n",
            "   - Define technical terms when they first appear.  \n",
            "   - Avoid using unexplained specialized terms.\n",
            "\n",
            "4. **Instructional Tone**  \n",
            "   - Maintain a clear, respectful, and instructional tone.  \n",
            "   - Avoid filler language or vague commentary.  \n",
            "   - Prioritize both correctness and clarity.\n",
            "\n",
            "5. **Underspecified Questions**  \n",
            "   - If the question lacks context, answer using standard physical theory.  \n",
            "   - Ask the student politely for clarification if needed.  \n",
            "   - Do not accept incorrect information uncritically.\n",
            "\n",
            "Your top priorities are:  \n",
            "**Mathematical and physical rigor**,  \n",
            "**Scientific truthfulness**,  \n",
            "**Clarity in photonic and quantum material reasoning**,  \n",
            "**Instructional effectiveness**,  \n",
            "**Respect for the learner’s understanding process**.\n",
            "\n",
            "### Input:\n",
            "What is the lattice constant 'a' for the element with the largest 'c' value in the hexagonal close-packed structure\n",
            "\n",
            "### Response:\n",
            "Based on the provided table for hexagonal close-packed structures and their c/a ratios, and assuming typical 'c' values (not all 'c' values are given, so this might require external knowledge not explicitly in the text for all elements, but the table does provide c/a which allows inference if 'c' or 'a' were known for one):\n",
            "\n",
            "* Among the elements listed, Cadmium (Cd) has the largest c/a ratio at 1.886. Its corresponding 'a' value is $2.98 \\text{ Å}$ (inferred from external sources often associated with this c/a, as the 'a' value is not directly given in the provided table for Cd, only its c/a ratio).\n",
            "* If we consider the 'c' value itself to be the largest, the sources do not explicitly provide the 'c' value for each element. They only provide the c/a ratio. Without the 'c' values, we cannot definitively identify the element with the largest 'c'. The table of crystal structures lists 'a' for several crystals, but not 'c' for hcp structures. For example, Mg is shown to have c/a 1.623, and its 'a' is $3.21 \\text{ Å}$. So its 'c' would be $3.21 \\times 1.623 = 5.21 \\text{ Å}$. Co has c/a 1.622, and 'a' is $2.51 \\text{ Å}$, so 'c' is $4.07 \\text{ Å}$. The source does not explicitly list 'c' for all entries in the c/a table, making it impossible to definitively answer based solely on the provided text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b964fb6a"
      },
      "source": [
        "## 加载预训练模型和 tokenizer\n",
        "\n",
        "### Subtask:\n",
        "加载 `Weyaxi/Einstein-v6.1-Llama3-8B` 模型及其对应的 Tokenizer。\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install flash-attn\n",
        "#--no-build-isolation --force-reinstall"
      ],
      "metadata": {
        "id": "BHpWj5vjlOGi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df30e0b0"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that flash_attn is installed, try loading the model and tokenizer again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "6656f54587914d81b8707c0913fda217",
            "58cf4fb70b654224b09a4722fcd3ba22",
            "9fef9de50dc945709a4c66d2e4c9a75a",
            "ac8252ea0d3e43548e38477a37034e2b",
            "00b1ceda69bb46038e1457f86ad0f7d7",
            "106bb20e73f24e23967d326f4025046b",
            "602262ce771a4c20b6a5ac7c377e0bdf",
            "9229a46d57ff46e49d188f60f99b61ac",
            "54f09a9ac76d408895be31f561e7c36b",
            "3ef7cde15bbc4d508d0f090de6c89c35",
            "85c5b0ef130e48f3a8765badc5ed6c21",
            "2dbbbea872e249559e03b02db39b3f3f",
            "cfacac2f9c124e0c8f53734db3fdaa56",
            "8fef12586fb3438a9eb8ce442833dd8e",
            "6fcb9c86cc8448c889b09a6b1932913f",
            "bad4fa8524244d4e81ec82ddff8c1871",
            "dd525f519f2a424d94a91442f0cee36b",
            "a13d1b84d8084cfe831ecd0e44658e55",
            "5620d5e2e0e24f28af97c539225d59aa",
            "f8d1644c475049828506e5c7f610670d",
            "dc009dbbfea34e86b5b367ace8bde3fd",
            "eb5fc23dfbbf4fffacd705edb0428e80",
            "25f36d6ed07249c9a69bdf9be7631634",
            "dbf4cd85419343629a08bda513572852",
            "2fea35b8c9a34238885c8fe4e54db56d",
            "b65be588f29948d7a402312332a56b73",
            "6b99c7b625164342856db1e26537725e",
            "77ffd49b4ace4e7a820fae05b1b6f130",
            "cc6c573956064bfd896e6c38d2b27456",
            "c430f709a6964d28ac9134d26b35656b",
            "8eb8676103a74905883ec6d6e1fb753c",
            "f0f55c8460844f5c8691a26b9c7ee9c7",
            "64b0c5bfd5e941a3a4804e9ea5f71db4"
          ]
        },
        "id": "88dcfc05",
        "outputId": "a7d7e28e-9c95-4013-d8b3-cedc86f21248"
      },
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "model_id = \"Weyaxi/Einstein-v6.1-Llama3-8B\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,                    # ✅ 开启 4-bit 量化\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,  # 计算时转为 bfloat16\n",
        "    bnb_4bit_use_double_quant=True,       # ✅ 启用双重量化\n",
        "    bnb_4bit_quant_type=\"nf4\",            # ✅ 使用 NF4 格式\n",
        ")\n",
        "def tokenize_function(examples):\n",
        "    # padding=\"max_length\" 和 truncation=True 确保所有输出序列长度一致\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", max_length=2048, truncation=True)\n",
        "# Load model with bfloat16, without FlashAttention 2\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,       # ✅ 绑定量化配置\n",
        "    device_map=\"auto\"\n",
        ").to(\"cuda\")  # 💡 Move model to GPU\n",
        "\n",
        "# Print confirmation\n",
        "print(\"Tokenizer loaded:\", tokenizer.__class__.__name__)\n",
        "print(\"Model loaded on device:\", next(model.parameters()).device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1194 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6656f54587914d81b8707c0913fda217"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/211 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dbbbea872e249559e03b02db39b3f3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25f36d6ed07249c9a69bdf9be7631634"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer loaded: PreTrainedTokenizerFast\n",
            "Model loaded on device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0d25206"
      },
      "source": [
        "## 配置 qlora\n",
        "\n",
        "### Subtask:\n",
        "设置 QLoRA 的相关参数，如 `r`, `lora_alpha`, `lora_dropout` 等。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4814b33c"
      },
      "source": [
        "**Reasoning**:\n",
        "Import LoraConfig and create a LoraConfig object with specified parameters for QLoRA fine-tuning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65d12fe9",
        "outputId": "2e782b86-d1b3-48dd-e71c-9737f6b70a1b"
      },
      "source": [
        "\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"down_proj\", \"up_proj\"],  # 所有 Linear 层\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "print(lora_config)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='Weyaxi/Einstein-v6.1-Llama3-8B', revision=None, inference_mode=False, r=16, target_modules={'k_proj', 'up_proj', 'gate_proj', 'down_proj', 'q_proj', 'o_proj', 'v_proj'}, exclude_modules=None, lora_alpha=64, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e8fd084"
      },
      "source": [
        "## 配置训练参数\n",
        "\n",
        "### Subtask:\n",
        "设置训练过程的参数，如 `num_train_epochs`, `per_device_train_batch_size`, `learning_rate` 等。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T6AU6qrdg5D",
        "outputId": "8c6d713b-c3f2-4be6-dc4f-6cd125a7064b"
      },
      "source": [
        "from transformers import TrainingArguments\n",
        "!wandb login\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=50,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    per_device_eval_batch_size=2,\n",
        "    #eval_accumulation_steps=32,\n",
        "    gradient_checkpointing=False,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    logging_steps=200,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False, # Set to True if using mixed precision training and your hardware supports it\n",
        "    bf16=torch.cuda.is_available(), # Set to True if using bfloat16 mixed precision training and your hardware supports it\n",
        "    max_grad_norm=0.3,\n",
        "    warmup_ratio=0.03,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"wandb\",\n",
        "    run_name=\"qlora-einstein-v6.1-run3\",\n",
        ")\n",
        "\n",
        "print(training_args)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mling7zhao\u001b[0m (\u001b[33mling7zhao-university-of-glasgow\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=200,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=8,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./results/runs/Aug03_20-00-21_6c90eb0bc551,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=200,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.CONSTANT,\n",
            "max_grad_norm=0.3,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=50,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=./results,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=2,\n",
            "per_device_train_batch_size=2,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=qlora-einstein-v6.1-run3,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=200,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.03,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.001,\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59040dd2"
      },
      "source": [
        "## 初始化 trainer\n",
        "\n",
        "### Subtask:\n",
        "使用加载的模型、处理好的数据、QLoRA 配置和训练参数初始化 `Trainer`。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507,
          "referenced_widgets": [
            "9f125069b89f4a1d9ff5f347ae656b1f",
            "6fdc4e8fd4724f7fb7fce4ee3a271b47",
            "172df847c9ab46c78b43919cbdb07ec1",
            "01ab1bc491344cc192a516d53d5c1036",
            "37bbaa7c401644008ef3021445c4640c",
            "df43b29d67084660b10e517b4e339b1e",
            "fe2413ba91134e99859f15e57cabefa3",
            "81d96256558140f991e12fb5e78f9cc1",
            "91ad00bdde5e4dafb7d61e605110e588",
            "64813d97f6674b83b5cfafb949ca52d7",
            "8c1244dc079c49e186ae5988f285e484",
            "add66cac664e4c04ae8d7048767cbd29",
            "4547a86f2f144a9a9db9b4fd3e0fdc73",
            "255687b6564f46bbace37a5435f74ac3",
            "e1bcd66e2062401bbe01739b7cd6311a",
            "1da5b410b3fe4359b6490099e82dbb9f",
            "f4985246588849ee8e64f45b955de405",
            "a901d1a763be496a80a8b52bfec37f29",
            "b2ccfe46b133468f9db288b7418ec54a",
            "846d73fe7839457099aadf9ebd756847",
            "3aae74089ca64aceb01ec9bd64217676",
            "0f2d656ef48d4a32a37b684c5cd00f42"
          ]
        },
        "id": "JF-DuqF4d7YG",
        "outputId": "666b6066-bf0c-4c37-ed7e-366f5c7bb7ee"
      },
      "source": [
        "!pip install kernels\n",
        "from trl import SFTTrainer\n",
        "import kernels\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset,\n",
        "    args=training_args,\n",
        "    peft_config=lora_config,\n",
        "    #compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(trainer)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kernels in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from kernels) (0.34.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from kernels) (25.0)\n",
            "Requirement already satisfied: pyyaml>=6 in /usr/local/lib/python3.11/dist-packages (from kernels) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1.0,>=0.26.0->kernels) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1.0,>=0.26.0->kernels) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1.0,>=0.26.0->kernels) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1.0,>=0.26.0->kernels) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1.0,>=0.26.0->kernels) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1.0,>=0.26.0->kernels) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub<1.0,>=0.26.0->kernels) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub<1.0,>=0.26.0->kernels) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub<1.0,>=0.26.0->kernels) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub<1.0,>=0.26.0->kernels) (2025.7.14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/mapping_func.py:79: UserWarning: The PEFT config's `base_model_name_or_path` was renamed from 'Weyaxi/Einstein-v6.1-Llama3-8B' to 'None'. Please ensure that the correct base model is loaded when loading this checkpoint.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/1194 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f125069b89f4a1d9ff5f347ae656b1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating eval dataset:   0%|          | 0/211 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "add66cac664e4c04ae8d7048767cbd29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<trl.trainer.sft_trainer.SFTTrainer object at 0x7b77edf305d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baebe817"
      },
      "source": [
        "## 开始训练\n",
        "\n",
        "### Subtask:\n",
        "执行模型微调训练。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "147fe273"
      },
      "source": [
        "**Reasoning**:\n",
        "Start the model fine-tuning training process using the initialized trainer object.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b654225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "c9deb069-8c11-4931-ebd7-c7786bfd5eaf"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mling7zhao\u001b[0m (\u001b[33mling7zhao-university-of-glasgow\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250803_200028-6ozdg16n</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ling7zhao-university-of-glasgow/huggingface/runs/6ozdg16n' target=\"_blank\">qlora-einstein-v6.1-run3</a></strong> to <a href='https://wandb.ai/ling7zhao-university-of-glasgow/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ling7zhao-university-of-glasgow/huggingface' target=\"_blank\">https://wandb.ai/ling7zhao-university-of-glasgow/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ling7zhao-university-of-glasgow/huggingface/runs/6ozdg16n' target=\"_blank\">https://wandb.ai/ling7zhao-university-of-glasgow/huggingface/runs/6ozdg16n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='681' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 681/3750 1:16:06 < 5:44:01, 0.15 it/s, Epoch 9.07/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.321400</td>\n",
              "      <td>0.404891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.077700</td>\n",
              "      <td>0.550248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.034800</td>\n",
              "      <td>0.568023</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3750/3750 7:01:25, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.321400</td>\n",
              "      <td>0.404891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.077700</td>\n",
              "      <td>0.550248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.034800</td>\n",
              "      <td>0.568023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.024400</td>\n",
              "      <td>0.618831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.020200</td>\n",
              "      <td>0.639058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.017800</td>\n",
              "      <td>0.658923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.016300</td>\n",
              "      <td>0.668836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.016600</td>\n",
              "      <td>0.671167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.016500</td>\n",
              "      <td>0.706637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.015600</td>\n",
              "      <td>0.691275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.015200</td>\n",
              "      <td>0.712587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.015200</td>\n",
              "      <td>0.714007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.014800</td>\n",
              "      <td>0.699806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.698520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.015200</td>\n",
              "      <td>0.700107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.014100</td>\n",
              "      <td>0.722602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.013400</td>\n",
              "      <td>0.736638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.013400</td>\n",
              "      <td>0.721229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3750, training_loss=0.03666259587605794, metrics={'train_runtime': 25294.652, 'train_samples_per_second': 2.36, 'train_steps_per_second': 0.148, 'total_flos': 2.768172936383693e+18, 'train_loss': 0.03666259587605794})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/qlora-adapter-only\")\n",
        "trainer.save_model(\"/content/qlora-finetuned-model\")\n",
        "tokenizer.save_pretrained(\"/content/qlora-finetuned-model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTC8KwIMqYs_",
        "outputId": "8a2a846c-19e0-4491-834f-52807cf07347"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/qlora-finetuned-model/tokenizer_config.json',\n",
              " '/content/qlora-finetuned-model/special_tokens_map.json',\n",
              " '/content/qlora-finetuned-model/chat_template.jinja',\n",
              " '/content/qlora-finetuned-model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"/content/qlora-finetuned-model\", 'zip', \"/content/qlora-finetuned-model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Yf3deKNltCS_",
        "outputId": "65f61729-1fbb-4688-9cf8-4a87dbc20c3c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/qlora-finetuned-model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cbb647c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to train failed due to a Flash Attention import error. While the `kernels` installation didn't fully resolve it, the environment might be in a state where training can proceed now. The next logical step is to attempt running `trainer.train()` again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "finetuned_model_path = \"/content/qlora-finetuned-model\"\n",
        "model = AutoModelForCausalLM.from_pretrained(finetuned_model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)\n",
        "\n",
        "# Set the model to evaluation mode and move it to the GPU\n",
        "model.eval()\n",
        "model.to(\"cuda\")\n",
        "\n",
        "print(\"Finetuned model loaded and set to evaluation mode.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "e31101d255d3498bb0bc3584329948bb",
            "3922ac9bfe764ee39d3bcd2ffd5ada94",
            "a8515287267146b6b31e099a860f37e6",
            "a28ca95b7c334a0aa251b5a1f00c089e",
            "4e27f15d531c4a9694adcc5c6da8c12d",
            "fef8f6c0120e4289b9f6b394a3ecde56",
            "438517d16fa1421ba986e43b13507958",
            "274099e88d2b43c2a82e21185bd87568",
            "3d8eda4f00584e6185f234d6b7fbf5fa",
            "08c054c91a264f4fb61246612839ceb6",
            "83a154bf5b054defbe7dad9fcad5147a"
          ]
        },
        "id": "bC0VVsjOtU8N",
        "outputId": "2609c158-6dc4-45a6-8185-6173cd7fd206"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e31101d255d3498bb0bc3584329948bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading adapter weights from /content/qlora-finetuned-model led to unexpected keys not found in the model: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight. Loading adapter weights from /content/qlora-finetuned-model led to missing keys in the model: model.layers.0.self_attn.q_proj.lora_A.default.weight, model.layers.0.self_attn.q_proj.lora_B.default.weight, model.layers.0.self_attn.k_proj.lora_A.default.weight, model.layers.0.self_attn.k_proj.lora_B.default.weight, model.layers.0.self_attn.v_proj.lora_A.default.weight, model.layers.0.self_attn.v_proj.lora_B.default.weight, model.layers.0.self_attn.o_proj.lora_A.default.weight, model.layers.0.self_attn.o_proj.lora_B.default.weight, model.layers.0.mlp.gate_proj.lora_A.default.weight, model.layers.0.mlp.gate_proj.lora_B.default.weight, model.layers.0.mlp.up_proj.lora_A.default.weight, model.layers.0.mlp.up_proj.lora_B.default.weight, model.layers.0.mlp.down_proj.lora_A.default.weight, model.layers.0.mlp.down_proj.lora_B.default.weight, model.layers.1.self_attn.q_proj.lora_A.default.weight, model.layers.1.self_attn.q_proj.lora_B.default.weight, model.layers.1.self_attn.k_proj.lora_A.default.weight, model.layers.1.self_attn.k_proj.lora_B.default.weight, model.layers.1.self_attn.v_proj.lora_A.default.weight, model.layers.1.self_attn.v_proj.lora_B.default.weight, model.layers.1.self_attn.o_proj.lora_A.default.weight, model.layers.1.self_attn.o_proj.lora_B.default.weight, model.layers.1.mlp.gate_proj.lora_A.default.weight, model.layers.1.mlp.gate_proj.lora_B.default.weight, model.layers.1.mlp.up_proj.lora_A.default.weight, model.layers.1.mlp.up_proj.lora_B.default.weight, model.layers.1.mlp.down_proj.lora_A.default.weight, model.layers.1.mlp.down_proj.lora_B.default.weight, model.layers.2.self_attn.q_proj.lora_A.default.weight, model.layers.2.self_attn.q_proj.lora_B.default.weight, model.layers.2.self_attn.k_proj.lora_A.default.weight, model.layers.2.self_attn.k_proj.lora_B.default.weight, model.layers.2.self_attn.v_proj.lora_A.default.weight, model.layers.2.self_attn.v_proj.lora_B.default.weight, model.layers.2.self_attn.o_proj.lora_A.default.weight, model.layers.2.self_attn.o_proj.lora_B.default.weight, model.layers.2.mlp.gate_proj.lora_A.default.weight, model.layers.2.mlp.gate_proj.lora_B.default.weight, model.layers.2.mlp.up_proj.lora_A.default.weight, model.layers.2.mlp.up_proj.lora_B.default.weight, model.layers.2.mlp.down_proj.lora_A.default.weight, model.layers.2.mlp.down_proj.lora_B.default.weight, model.layers.3.self_attn.q_proj.lora_A.default.weight, model.layers.3.self_attn.q_proj.lora_B.default.weight, model.layers.3.self_attn.k_proj.lora_A.default.weight, model.layers.3.self_attn.k_proj.lora_B.default.weight, model.layers.3.self_attn.v_proj.lora_A.default.weight, model.layers.3.self_attn.v_proj.lora_B.default.weight, model.layers.3.self_attn.o_proj.lora_A.default.weight, model.layers.3.self_attn.o_proj.lora_B.default.weight, model.layers.3.mlp.gate_proj.lora_A.default.weight, model.layers.3.mlp.gate_proj.lora_B.default.weight, model.layers.3.mlp.up_proj.lora_A.default.weight, model.layers.3.mlp.up_proj.lora_B.default.weight, model.layers.3.mlp.down_proj.lora_A.default.weight, model.layers.3.mlp.down_proj.lora_B.default.weight, model.layers.4.self_attn.q_proj.lora_A.default.weight, model.layers.4.self_attn.q_proj.lora_B.default.weight, model.layers.4.self_attn.k_proj.lora_A.default.weight, model.layers.4.self_attn.k_proj.lora_B.default.weight, model.layers.4.self_attn.v_proj.lora_A.default.weight, model.layers.4.self_attn.v_proj.lora_B.default.weight, model.layers.4.self_attn.o_proj.lora_A.default.weight, model.layers.4.self_attn.o_proj.lora_B.default.weight, model.layers.4.mlp.gate_proj.lora_A.default.weight, model.layers.4.mlp.gate_proj.lora_B.default.weight, model.layers.4.mlp.up_proj.lora_A.default.weight, model.layers.4.mlp.up_proj.lora_B.default.weight, model.layers.4.mlp.down_proj.lora_A.default.weight, model.layers.4.mlp.down_proj.lora_B.default.weight, model.layers.5.self_attn.q_proj.lora_A.default.weight, model.layers.5.self_attn.q_proj.lora_B.default.weight, model.layers.5.self_attn.k_proj.lora_A.default.weight, model.layers.5.self_attn.k_proj.lora_B.default.weight, model.layers.5.self_attn.v_proj.lora_A.default.weight, model.layers.5.self_attn.v_proj.lora_B.default.weight, model.layers.5.self_attn.o_proj.lora_A.default.weight, model.layers.5.self_attn.o_proj.lora_B.default.weight, model.layers.5.mlp.gate_proj.lora_A.default.weight, model.layers.5.mlp.gate_proj.lora_B.default.weight, model.layers.5.mlp.up_proj.lora_A.default.weight, model.layers.5.mlp.up_proj.lora_B.default.weight, model.layers.5.mlp.down_proj.lora_A.default.weight, model.layers.5.mlp.down_proj.lora_B.default.weight, model.layers.6.self_attn.q_proj.lora_A.default.weight, model.layers.6.self_attn.q_proj.lora_B.default.weight, model.layers.6.self_attn.k_proj.lora_A.default.weight, model.layers.6.self_attn.k_proj.lora_B.default.weight, model.layers.6.self_attn.v_proj.lora_A.default.weight, model.layers.6.self_attn.v_proj.lora_B.default.weight, model.layers.6.self_attn.o_proj.lora_A.default.weight, model.layers.6.self_attn.o_proj.lora_B.default.weight, model.layers.6.mlp.gate_proj.lora_A.default.weight, model.layers.6.mlp.gate_proj.lora_B.default.weight, model.layers.6.mlp.up_proj.lora_A.default.weight, model.layers.6.mlp.up_proj.lora_B.default.weight, model.layers.6.mlp.down_proj.lora_A.default.weight, model.layers.6.mlp.down_proj.lora_B.default.weight, model.layers.7.self_attn.q_proj.lora_A.default.weight, model.layers.7.self_attn.q_proj.lora_B.default.weight, model.layers.7.self_attn.k_proj.lora_A.default.weight, model.layers.7.self_attn.k_proj.lora_B.default.weight, model.layers.7.self_attn.v_proj.lora_A.default.weight, model.layers.7.self_attn.v_proj.lora_B.default.weight, model.layers.7.self_attn.o_proj.lora_A.default.weight, model.layers.7.self_attn.o_proj.lora_B.default.weight, model.layers.7.mlp.gate_proj.lora_A.default.weight, model.layers.7.mlp.gate_proj.lora_B.default.weight, model.layers.7.mlp.up_proj.lora_A.default.weight, model.layers.7.mlp.up_proj.lora_B.default.weight, model.layers.7.mlp.down_proj.lora_A.default.weight, model.layers.7.mlp.down_proj.lora_B.default.weight, model.layers.8.self_attn.q_proj.lora_A.default.weight, model.layers.8.self_attn.q_proj.lora_B.default.weight, model.layers.8.self_attn.k_proj.lora_A.default.weight, model.layers.8.self_attn.k_proj.lora_B.default.weight, model.layers.8.self_attn.v_proj.lora_A.default.weight, model.layers.8.self_attn.v_proj.lora_B.default.weight, model.layers.8.self_attn.o_proj.lora_A.default.weight, model.layers.8.self_attn.o_proj.lora_B.default.weight, model.layers.8.mlp.gate_proj.lora_A.default.weight, model.layers.8.mlp.gate_proj.lora_B.default.weight, model.layers.8.mlp.up_proj.lora_A.default.weight, model.layers.8.mlp.up_proj.lora_B.default.weight, model.layers.8.mlp.down_proj.lora_A.default.weight, model.layers.8.mlp.down_proj.lora_B.default.weight, model.layers.9.self_attn.q_proj.lora_A.default.weight, model.layers.9.self_attn.q_proj.lora_B.default.weight, model.layers.9.self_attn.k_proj.lora_A.default.weight, model.layers.9.self_attn.k_proj.lora_B.default.weight, model.layers.9.self_attn.v_proj.lora_A.default.weight, model.layers.9.self_attn.v_proj.lora_B.default.weight, model.layers.9.self_attn.o_proj.lora_A.default.weight, model.layers.9.self_attn.o_proj.lora_B.default.weight, model.layers.9.mlp.gate_proj.lora_A.default.weight, model.layers.9.mlp.gate_proj.lora_B.default.weight, model.layers.9.mlp.up_proj.lora_A.default.weight, model.layers.9.mlp.up_proj.lora_B.default.weight, model.layers.9.mlp.down_proj.lora_A.default.weight, model.layers.9.mlp.down_proj.lora_B.default.weight, model.layers.10.self_attn.q_proj.lora_A.default.weight, model.layers.10.self_attn.q_proj.lora_B.default.weight, model.layers.10.self_attn.k_proj.lora_A.default.weight, model.layers.10.self_attn.k_proj.lora_B.default.weight, model.layers.10.self_attn.v_proj.lora_A.default.weight, model.layers.10.self_attn.v_proj.lora_B.default.weight, model.layers.10.self_attn.o_proj.lora_A.default.weight, model.layers.10.self_attn.o_proj.lora_B.default.weight, model.layers.10.mlp.gate_proj.lora_A.default.weight, model.layers.10.mlp.gate_proj.lora_B.default.weight, model.layers.10.mlp.up_proj.lora_A.default.weight, model.layers.10.mlp.up_proj.lora_B.default.weight, model.layers.10.mlp.down_proj.lora_A.default.weight, model.layers.10.mlp.down_proj.lora_B.default.weight, model.layers.11.self_attn.q_proj.lora_A.default.weight, model.layers.11.self_attn.q_proj.lora_B.default.weight, model.layers.11.self_attn.k_proj.lora_A.default.weight, model.layers.11.self_attn.k_proj.lora_B.default.weight, model.layers.11.self_attn.v_proj.lora_A.default.weight, model.layers.11.self_attn.v_proj.lora_B.default.weight, model.layers.11.self_attn.o_proj.lora_A.default.weight, model.layers.11.self_attn.o_proj.lora_B.default.weight, model.layers.11.mlp.gate_proj.lora_A.default.weight, model.layers.11.mlp.gate_proj.lora_B.default.weight, model.layers.11.mlp.up_proj.lora_A.default.weight, model.layers.11.mlp.up_proj.lora_B.default.weight, model.layers.11.mlp.down_proj.lora_A.default.weight, model.layers.11.mlp.down_proj.lora_B.default.weight, model.layers.12.self_attn.q_proj.lora_A.default.weight, model.layers.12.self_attn.q_proj.lora_B.default.weight, model.layers.12.self_attn.k_proj.lora_A.default.weight, model.layers.12.self_attn.k_proj.lora_B.default.weight, model.layers.12.self_attn.v_proj.lora_A.default.weight, model.layers.12.self_attn.v_proj.lora_B.default.weight, model.layers.12.self_attn.o_proj.lora_A.default.weight, model.layers.12.self_attn.o_proj.lora_B.default.weight, model.layers.12.mlp.gate_proj.lora_A.default.weight, model.layers.12.mlp.gate_proj.lora_B.default.weight, model.layers.12.mlp.up_proj.lora_A.default.weight, model.layers.12.mlp.up_proj.lora_B.default.weight, model.layers.12.mlp.down_proj.lora_A.default.weight, model.layers.12.mlp.down_proj.lora_B.default.weight, model.layers.13.self_attn.q_proj.lora_A.default.weight, model.layers.13.self_attn.q_proj.lora_B.default.weight, model.layers.13.self_attn.k_proj.lora_A.default.weight, model.layers.13.self_attn.k_proj.lora_B.default.weight, model.layers.13.self_attn.v_proj.lora_A.default.weight, model.layers.13.self_attn.v_proj.lora_B.default.weight, model.layers.13.self_attn.o_proj.lora_A.default.weight, model.layers.13.self_attn.o_proj.lora_B.default.weight, model.layers.13.mlp.gate_proj.lora_A.default.weight, model.layers.13.mlp.gate_proj.lora_B.default.weight, model.layers.13.mlp.up_proj.lora_A.default.weight, model.layers.13.mlp.up_proj.lora_B.default.weight, model.layers.13.mlp.down_proj.lora_A.default.weight, model.layers.13.mlp.down_proj.lora_B.default.weight, model.layers.14.self_attn.q_proj.lora_A.default.weight, model.layers.14.self_attn.q_proj.lora_B.default.weight, model.layers.14.self_attn.k_proj.lora_A.default.weight, model.layers.14.self_attn.k_proj.lora_B.default.weight, model.layers.14.self_attn.v_proj.lora_A.default.weight, model.layers.14.self_attn.v_proj.lora_B.default.weight, model.layers.14.self_attn.o_proj.lora_A.default.weight, model.layers.14.self_attn.o_proj.lora_B.default.weight, model.layers.14.mlp.gate_proj.lora_A.default.weight, model.layers.14.mlp.gate_proj.lora_B.default.weight, model.layers.14.mlp.up_proj.lora_A.default.weight, model.layers.14.mlp.up_proj.lora_B.default.weight, model.layers.14.mlp.down_proj.lora_A.default.weight, model.layers.14.mlp.down_proj.lora_B.default.weight, model.layers.15.self_attn.q_proj.lora_A.default.weight, model.layers.15.self_attn.q_proj.lora_B.default.weight, model.layers.15.self_attn.k_proj.lora_A.default.weight, model.layers.15.self_attn.k_proj.lora_B.default.weight, model.layers.15.self_attn.v_proj.lora_A.default.weight, model.layers.15.self_attn.v_proj.lora_B.default.weight, model.layers.15.self_attn.o_proj.lora_A.default.weight, model.layers.15.self_attn.o_proj.lora_B.default.weight, model.layers.15.mlp.gate_proj.lora_A.default.weight, model.layers.15.mlp.gate_proj.lora_B.default.weight, model.layers.15.mlp.up_proj.lora_A.default.weight, model.layers.15.mlp.up_proj.lora_B.default.weight, model.layers.15.mlp.down_proj.lora_A.default.weight, model.layers.15.mlp.down_proj.lora_B.default.weight, model.layers.16.self_attn.q_proj.lora_A.default.weight, model.layers.16.self_attn.q_proj.lora_B.default.weight, model.layers.16.self_attn.k_proj.lora_A.default.weight, model.layers.16.self_attn.k_proj.lora_B.default.weight, model.layers.16.self_attn.v_proj.lora_A.default.weight, model.layers.16.self_attn.v_proj.lora_B.default.weight, model.layers.16.self_attn.o_proj.lora_A.default.weight, model.layers.16.self_attn.o_proj.lora_B.default.weight, model.layers.16.mlp.gate_proj.lora_A.default.weight, model.layers.16.mlp.gate_proj.lora_B.default.weight, model.layers.16.mlp.up_proj.lora_A.default.weight, model.layers.16.mlp.up_proj.lora_B.default.weight, model.layers.16.mlp.down_proj.lora_A.default.weight, model.layers.16.mlp.down_proj.lora_B.default.weight, model.layers.17.self_attn.q_proj.lora_A.default.weight, model.layers.17.self_attn.q_proj.lora_B.default.weight, model.layers.17.self_attn.k_proj.lora_A.default.weight, model.layers.17.self_attn.k_proj.lora_B.default.weight, model.layers.17.self_attn.v_proj.lora_A.default.weight, model.layers.17.self_attn.v_proj.lora_B.default.weight, model.layers.17.self_attn.o_proj.lora_A.default.weight, model.layers.17.self_attn.o_proj.lora_B.default.weight, model.layers.17.mlp.gate_proj.lora_A.default.weight, model.layers.17.mlp.gate_proj.lora_B.default.weight, model.layers.17.mlp.up_proj.lora_A.default.weight, model.layers.17.mlp.up_proj.lora_B.default.weight, model.layers.17.mlp.down_proj.lora_A.default.weight, model.layers.17.mlp.down_proj.lora_B.default.weight, model.layers.18.self_attn.q_proj.lora_A.default.weight, model.layers.18.self_attn.q_proj.lora_B.default.weight, model.layers.18.self_attn.k_proj.lora_A.default.weight, model.layers.18.self_attn.k_proj.lora_B.default.weight, model.layers.18.self_attn.v_proj.lora_A.default.weight, model.layers.18.self_attn.v_proj.lora_B.default.weight, model.layers.18.self_attn.o_proj.lora_A.default.weight, model.layers.18.self_attn.o_proj.lora_B.default.weight, model.layers.18.mlp.gate_proj.lora_A.default.weight, model.layers.18.mlp.gate_proj.lora_B.default.weight, model.layers.18.mlp.up_proj.lora_A.default.weight, model.layers.18.mlp.up_proj.lora_B.default.weight, model.layers.18.mlp.down_proj.lora_A.default.weight, model.layers.18.mlp.down_proj.lora_B.default.weight, model.layers.19.self_attn.q_proj.lora_A.default.weight, model.layers.19.self_attn.q_proj.lora_B.default.weight, model.layers.19.self_attn.k_proj.lora_A.default.weight, model.layers.19.self_attn.k_proj.lora_B.default.weight, model.layers.19.self_attn.v_proj.lora_A.default.weight, model.layers.19.self_attn.v_proj.lora_B.default.weight, model.layers.19.self_attn.o_proj.lora_A.default.weight, model.layers.19.self_attn.o_proj.lora_B.default.weight, model.layers.19.mlp.gate_proj.lora_A.default.weight, model.layers.19.mlp.gate_proj.lora_B.default.weight, model.layers.19.mlp.up_proj.lora_A.default.weight, model.layers.19.mlp.up_proj.lora_B.default.weight, model.layers.19.mlp.down_proj.lora_A.default.weight, model.layers.19.mlp.down_proj.lora_B.default.weight, model.layers.20.self_attn.q_proj.lora_A.default.weight, model.layers.20.self_attn.q_proj.lora_B.default.weight, model.layers.20.self_attn.k_proj.lora_A.default.weight, model.layers.20.self_attn.k_proj.lora_B.default.weight, model.layers.20.self_attn.v_proj.lora_A.default.weight, model.layers.20.self_attn.v_proj.lora_B.default.weight, model.layers.20.self_attn.o_proj.lora_A.default.weight, model.layers.20.self_attn.o_proj.lora_B.default.weight, model.layers.20.mlp.gate_proj.lora_A.default.weight, model.layers.20.mlp.gate_proj.lora_B.default.weight, model.layers.20.mlp.up_proj.lora_A.default.weight, model.layers.20.mlp.up_proj.lora_B.default.weight, model.layers.20.mlp.down_proj.lora_A.default.weight, model.layers.20.mlp.down_proj.lora_B.default.weight, model.layers.21.self_attn.q_proj.lora_A.default.weight, model.layers.21.self_attn.q_proj.lora_B.default.weight, model.layers.21.self_attn.k_proj.lora_A.default.weight, model.layers.21.self_attn.k_proj.lora_B.default.weight, model.layers.21.self_attn.v_proj.lora_A.default.weight, model.layers.21.self_attn.v_proj.lora_B.default.weight, model.layers.21.self_attn.o_proj.lora_A.default.weight, model.layers.21.self_attn.o_proj.lora_B.default.weight, model.layers.21.mlp.gate_proj.lora_A.default.weight, model.layers.21.mlp.gate_proj.lora_B.default.weight, model.layers.21.mlp.up_proj.lora_A.default.weight, model.layers.21.mlp.up_proj.lora_B.default.weight, model.layers.21.mlp.down_proj.lora_A.default.weight, model.layers.21.mlp.down_proj.lora_B.default.weight, model.layers.22.self_attn.q_proj.lora_A.default.weight, model.layers.22.self_attn.q_proj.lora_B.default.weight, model.layers.22.self_attn.k_proj.lora_A.default.weight, model.layers.22.self_attn.k_proj.lora_B.default.weight, model.layers.22.self_attn.v_proj.lora_A.default.weight, model.layers.22.self_attn.v_proj.lora_B.default.weight, model.layers.22.self_attn.o_proj.lora_A.default.weight, model.layers.22.self_attn.o_proj.lora_B.default.weight, model.layers.22.mlp.gate_proj.lora_A.default.weight, model.layers.22.mlp.gate_proj.lora_B.default.weight, model.layers.22.mlp.up_proj.lora_A.default.weight, model.layers.22.mlp.up_proj.lora_B.default.weight, model.layers.22.mlp.down_proj.lora_A.default.weight, model.layers.22.mlp.down_proj.lora_B.default.weight, model.layers.23.self_attn.q_proj.lora_A.default.weight, model.layers.23.self_attn.q_proj.lora_B.default.weight, model.layers.23.self_attn.k_proj.lora_A.default.weight, model.layers.23.self_attn.k_proj.lora_B.default.weight, model.layers.23.self_attn.v_proj.lora_A.default.weight, model.layers.23.self_attn.v_proj.lora_B.default.weight, model.layers.23.self_attn.o_proj.lora_A.default.weight, model.layers.23.self_attn.o_proj.lora_B.default.weight, model.layers.23.mlp.gate_proj.lora_A.default.weight, model.layers.23.mlp.gate_proj.lora_B.default.weight, model.layers.23.mlp.up_proj.lora_A.default.weight, model.layers.23.mlp.up_proj.lora_B.default.weight, model.layers.23.mlp.down_proj.lora_A.default.weight, model.layers.23.mlp.down_proj.lora_B.default.weight, model.layers.24.self_attn.q_proj.lora_A.default.weight, model.layers.24.self_attn.q_proj.lora_B.default.weight, model.layers.24.self_attn.k_proj.lora_A.default.weight, model.layers.24.self_attn.k_proj.lora_B.default.weight, model.layers.24.self_attn.v_proj.lora_A.default.weight, model.layers.24.self_attn.v_proj.lora_B.default.weight, model.layers.24.self_attn.o_proj.lora_A.default.weight, model.layers.24.self_attn.o_proj.lora_B.default.weight, model.layers.24.mlp.gate_proj.lora_A.default.weight, model.layers.24.mlp.gate_proj.lora_B.default.weight, model.layers.24.mlp.up_proj.lora_A.default.weight, model.layers.24.mlp.up_proj.lora_B.default.weight, model.layers.24.mlp.down_proj.lora_A.default.weight, model.layers.24.mlp.down_proj.lora_B.default.weight, model.layers.25.self_attn.q_proj.lora_A.default.weight, model.layers.25.self_attn.q_proj.lora_B.default.weight, model.layers.25.self_attn.k_proj.lora_A.default.weight, model.layers.25.self_attn.k_proj.lora_B.default.weight, model.layers.25.self_attn.v_proj.lora_A.default.weight, model.layers.25.self_attn.v_proj.lora_B.default.weight, model.layers.25.self_attn.o_proj.lora_A.default.weight, model.layers.25.self_attn.o_proj.lora_B.default.weight, model.layers.25.mlp.gate_proj.lora_A.default.weight, model.layers.25.mlp.gate_proj.lora_B.default.weight, model.layers.25.mlp.up_proj.lora_A.default.weight, model.layers.25.mlp.up_proj.lora_B.default.weight, model.layers.25.mlp.down_proj.lora_A.default.weight, model.layers.25.mlp.down_proj.lora_B.default.weight, model.layers.26.self_attn.q_proj.lora_A.default.weight, model.layers.26.self_attn.q_proj.lora_B.default.weight, model.layers.26.self_attn.k_proj.lora_A.default.weight, model.layers.26.self_attn.k_proj.lora_B.default.weight, model.layers.26.self_attn.v_proj.lora_A.default.weight, model.layers.26.self_attn.v_proj.lora_B.default.weight, model.layers.26.self_attn.o_proj.lora_A.default.weight, model.layers.26.self_attn.o_proj.lora_B.default.weight, model.layers.26.mlp.gate_proj.lora_A.default.weight, model.layers.26.mlp.gate_proj.lora_B.default.weight, model.layers.26.mlp.up_proj.lora_A.default.weight, model.layers.26.mlp.up_proj.lora_B.default.weight, model.layers.26.mlp.down_proj.lora_A.default.weight, model.layers.26.mlp.down_proj.lora_B.default.weight, model.layers.27.self_attn.q_proj.lora_A.default.weight, model.layers.27.self_attn.q_proj.lora_B.default.weight, model.layers.27.self_attn.k_proj.lora_A.default.weight, model.layers.27.self_attn.k_proj.lora_B.default.weight, model.layers.27.self_attn.v_proj.lora_A.default.weight, model.layers.27.self_attn.v_proj.lora_B.default.weight, model.layers.27.self_attn.o_proj.lora_A.default.weight, model.layers.27.self_attn.o_proj.lora_B.default.weight, model.layers.27.mlp.gate_proj.lora_A.default.weight, model.layers.27.mlp.gate_proj.lora_B.default.weight, model.layers.27.mlp.up_proj.lora_A.default.weight, model.layers.27.mlp.up_proj.lora_B.default.weight, model.layers.27.mlp.down_proj.lora_A.default.weight, model.layers.27.mlp.down_proj.lora_B.default.weight, model.layers.28.self_attn.q_proj.lora_A.default.weight, model.layers.28.self_attn.q_proj.lora_B.default.weight, model.layers.28.self_attn.k_proj.lora_A.default.weight, model.layers.28.self_attn.k_proj.lora_B.default.weight, model.layers.28.self_attn.v_proj.lora_A.default.weight, model.layers.28.self_attn.v_proj.lora_B.default.weight, model.layers.28.self_attn.o_proj.lora_A.default.weight, model.layers.28.self_attn.o_proj.lora_B.default.weight, model.layers.28.mlp.gate_proj.lora_A.default.weight, model.layers.28.mlp.gate_proj.lora_B.default.weight, model.layers.28.mlp.up_proj.lora_A.default.weight, model.layers.28.mlp.up_proj.lora_B.default.weight, model.layers.28.mlp.down_proj.lora_A.default.weight, model.layers.28.mlp.down_proj.lora_B.default.weight, model.layers.29.self_attn.q_proj.lora_A.default.weight, model.layers.29.self_attn.q_proj.lora_B.default.weight, model.layers.29.self_attn.k_proj.lora_A.default.weight, model.layers.29.self_attn.k_proj.lora_B.default.weight, model.layers.29.self_attn.v_proj.lora_A.default.weight, model.layers.29.self_attn.v_proj.lora_B.default.weight, model.layers.29.self_attn.o_proj.lora_A.default.weight, model.layers.29.self_attn.o_proj.lora_B.default.weight, model.layers.29.mlp.gate_proj.lora_A.default.weight, model.layers.29.mlp.gate_proj.lora_B.default.weight, model.layers.29.mlp.up_proj.lora_A.default.weight, model.layers.29.mlp.up_proj.lora_B.default.weight, model.layers.29.mlp.down_proj.lora_A.default.weight, model.layers.29.mlp.down_proj.lora_B.default.weight, model.layers.30.self_attn.q_proj.lora_A.default.weight, model.layers.30.self_attn.q_proj.lora_B.default.weight, model.layers.30.self_attn.k_proj.lora_A.default.weight, model.layers.30.self_attn.k_proj.lora_B.default.weight, model.layers.30.self_attn.v_proj.lora_A.default.weight, model.layers.30.self_attn.v_proj.lora_B.default.weight, model.layers.30.self_attn.o_proj.lora_A.default.weight, model.layers.30.self_attn.o_proj.lora_B.default.weight, model.layers.30.mlp.gate_proj.lora_A.default.weight, model.layers.30.mlp.gate_proj.lora_B.default.weight, model.layers.30.mlp.up_proj.lora_A.default.weight, model.layers.30.mlp.up_proj.lora_B.default.weight, model.layers.30.mlp.down_proj.lora_A.default.weight, model.layers.30.mlp.down_proj.lora_B.default.weight, model.layers.31.self_attn.q_proj.lora_A.default.weight, model.layers.31.self_attn.q_proj.lora_B.default.weight, model.layers.31.self_attn.k_proj.lora_A.default.weight, model.layers.31.self_attn.k_proj.lora_B.default.weight, model.layers.31.self_attn.v_proj.lora_A.default.weight, model.layers.31.self_attn.v_proj.lora_B.default.weight, model.layers.31.self_attn.o_proj.lora_A.default.weight, model.layers.31.self_attn.o_proj.lora_B.default.weight, model.layers.31.mlp.gate_proj.lora_A.default.weight, model.layers.31.mlp.gate_proj.lora_B.default.weight, model.layers.31.mlp.up_proj.lora_A.default.weight, model.layers.31.mlp.up_proj.lora_B.default.weight, model.layers.31.mlp.down_proj.lora_A.default.weight, model.layers.31.mlp.down_proj.lora_B.default.weight\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finetuned model loaded and set to evaluation mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "608a3c47",
        "outputId": "d66b7598-e63f-4e64-f54e-9d2f4f62268f"
      },
      "source": [
        "# Example inference\n",
        "prompt = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\nWhat is the significance of the distance $d$ in the context of lattice planes and reciprocal lattice vectors？<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate response\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=500,\n",
        "        num_return_sequences=1,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7,\n",
        "        #repetition_penalty=1.1\n",
        "    )\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user\n",
            "What is the significance of the distance $d$ in the context of lattice planes and reciprocal lattice vectors？assistant.weixin\n",
            "The distance $d$ is a crucial parameter in the context of lattice planes and reciprocal lattice vectors. It represents the interplanar spacing, which is the distance between adjacent lattice planes. This distance is directly related to the diffraction pattern observed in X-ray diffraction experiments, as well as the positions of Bragg peaks in the diffraction pattern.\n",
            "\n",
            "The reciprocal lattice vectors are a set of vectors that are orthogonal to the lattice planes and have a magnitude that is inversely proportional to the interplanar spacing. In other words, the reciprocal lattice vectors are a mathematical tool used to describe the structure of the crystal lattice in terms of its periodicity and symmetry.\n",
            "\n",
            "The distance $d$ plays a significant role in determining the direction and intensity of the Bragg peaks in the diffraction pattern. The Bragg peaks occur when the path difference between rays scattered by adjacent lattice planes is equal to an integer multiple of the wavelength of the incident X-ray beam. This condition can be expressed as:\n",
            "\n",
            "$n\\lambda = 2d\\sin\\theta$\n",
            "\n",
            "where $n$ is an integer, $\\lambda$ is the wavelength of the X-ray beam, and $\\theta$ is the angle of incidence of the X-ray beam with respect to the lattice planes.\n",
            "\n",
            "In summary, the distance $d$ is an important parameter in the context of lattice planes and reciprocal lattice vectors because it determines the interplanar spacing, which in turn affects the diffraction pattern observed in X-ray diffraction experiments. The reciprocal lattice vectors are used to describe the crystal lattice in terms of its periodicity and symmetry, and the distance $d$ plays a significant role in determining the direction and intensity of the Bragg peaks in the diffraction pattern.\n",
            "A1: The distance $d$ is a crucial parameter in the context of lattice planes and reciprocal lattice vectors. It represents the interplanar spacing, which is the distance between adjacent lattice planes. This distance is directly related to the diffraction pattern observed in X-ray diffraction experiments, as well as the positions of Bragg peaks in the diffraction pattern. The reciprocal lattice vectors are a set of vectors that are orthogonal to the lattice planes and have a magnitude that is inversely proportional to the interplanar spacing. In other words, the reciprocal lattice vectors are a mathematical tool used to describe the structure of the crystal lattice in terms of its periodicity and symmetry. The distance $d$ plays a significant role in determining the direction and intensity of the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "# Load the test dataset\n",
        "test_dataset_path = \"/content/test_100.json\"\n",
        "test_dataset = load_dataset(\"json\", data_files=test_dataset_path, split=\"train\")\n",
        "\n",
        "# Select 20 examples from the test set\n",
        "num_examples = 20\n",
        "selected_examples = test_dataset.select(range(num_examples))\n",
        "\n",
        "results = []\n",
        "\n",
        "# Ensure model and tokenizer are loaded and on the correct device (assuming they were loaded in previous cells)\n",
        "# model.eval() # Assuming model is already in eval mode\n",
        "# model.to(\"cuda\") # Assuming model is already on cuda\n",
        "\n",
        "for example in selected_examples:\n",
        "    instruction = example['instruction']\n",
        "    ground_truth_output = example['output']\n",
        "\n",
        "    # Format the prompt for inference\n",
        "    prompt = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n{example.get('system', '')}<|eot_id|>\"\n",
        "    if example.get('input') and example['input'].strip():\n",
        "        prompt += f\"<|start_header_id|>user<|end_header_id|>\\n{instruction}\\n{example['input']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
        "    else:\n",
        "        prompt += f\"<|start_header_id|>user<|end_header_id|>\\n{instruction}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
        "\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=600, # Increased max_new_tokens for potentially longer responses\n",
        "            num_return_sequences=1,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.93,\n",
        "            temperature=0.6\n",
        "        )\n",
        "\n",
        "    generated_response = tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True)\n",
        "\n",
        "    results.append({\n",
        "        \"Instruction\": instruction,\n",
        "        \"Generated Output\": generated_response,\n",
        "        \"Ground Truth Output\": ground_truth_output\n",
        "    })\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Display the DataFrame\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "Y3CsIePVwlHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70c94a08"
      },
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "results_df.to_csv(\"inference_results.csv\", index=False)\n",
        "\n",
        "print(\"DataFrame saved to inference_results.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96fdf4d5"
      },
      "source": [
        "您可以使用左侧的文件浏览器找到 `inference_results.csv` 文件，然后右键点击下载。或者，您也可以运行以下代码来下载文件："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81b6a673"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"inference_results.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}